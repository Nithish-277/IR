{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,json\n",
    "from bs4 import BeautifulSoup\n",
    "from msedge.selenium_tools import Edge,EdgeOptions\n",
    "from selenium import webdriver\n",
    "\n",
    "def get_url(search_term,page):\n",
    "    template = \"https://www.amazon.in/s?k={}&ref=nb_sb_noss\"\n",
    "    search_term = search_term.replace(' ','+')\n",
    "    #add item query\n",
    "    url = template.format(search_term)\n",
    "    #add page query placeholder\n",
    "    url+='&page={}'.format(page)\n",
    "    return url\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record \"\"\"\n",
    "    #description and url\n",
    "    try:\n",
    "        atag = item.h2.a\n",
    "        description = atag.text.strip()\n",
    "        url = 'https://www.amazon.in/' + atag.get('href')\n",
    "    except AttributeError:\n",
    "        description = ''\n",
    "        return\n",
    "    #price\n",
    "    try:\n",
    "        price_parent = item.find('span','a-price')\n",
    "        price = price_parent.find('span','a-offscreen').text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    #rating\n",
    "    try:\n",
    "        rating = item.i.text\n",
    "        review_count = item.find('span',{'class' : 'a-size-base','dir':'auto'}).text\n",
    "    except AttributeError:\n",
    "        rating = ''\n",
    "        review_count = ''\n",
    "    \n",
    "    result = (description,price,rating,review_count,url)\n",
    "    return result\n",
    "\n",
    "def main(searchTerms):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    \n",
    "    #startup the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    records = []\n",
    "    i = 0\n",
    "    for term in searchTerms:        \n",
    "        print(i)\n",
    "#         url = get_url(term[0],1)\n",
    "#         driver.get(url)\n",
    "        for page in range(1,21):\n",
    "            page_url = get_url(term[0],page)\n",
    "            print(page_url)\n",
    "            driver.get(page_url)\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            results = soup.find_all('div',{'data-component-type' : 's-search-result'})\n",
    "            for item in results:\n",
    "                record = extract_record(item)\n",
    "                records.append(record)\n",
    "        i = i + 1\n",
    "    driver.close()\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Keywords from 'finalKeywords.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "keywords = pd.read_csv('finalKeywords.csv',header = None)\n",
    "keywords = keywords.iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = main(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Crawled Data into Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    outF = open(str(i+1) + \".txt\", \"w\",encoding = 'utf-8')\n",
    "    if data[i]:\n",
    "        for line in data[i]:\n",
    "      # write line to output file\n",
    "            outF.write(line)\n",
    "            outF.write(\"\\n\")\n",
    "outF.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
