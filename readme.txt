Three files were zipped.

All the Codes I have executed in JUPYTER NOTEBOOK

1) keywordsCrawling.py && keywordsCrawling.ipynb
2) dataScraping.py && dataScraping.ipynb
2) task1_task2.py && task1_task2.ipynb

All the files should be saved in a single folder and the main dataset folder should have all text files in it.
While storing the output in a local file the path should set accordingly in path variable.

In Preprocessing, stopwords should be eliminated , so from nltk module stopwords should be imported
	--> code line for downloading stopwrods is 'from nltk.corpus import stopwords'

Here, Main Inverted Index is created and it takes 10-15 minutes.
Inverted Index is also stored in Text File

Code for Scraped data can be found in 'dataScraping.py' file, if we want to scrap the data freshly it takes 132 minutes.
Selenium module has to be installed, command to install selenium module is 'pip install -U selenium'
chromedriver should be installed and have to save in the present running folder.

Code for Task1 and Task2 can be found in 'task1_task2.py' or 'taks1_task2.ipynb' files and if we run the cell creating Inverted Index it nearly takes 10-15 minutes.

Project Report is also attached and the total implementation of Task1 and Task2 can be found in Project Documentation
 

